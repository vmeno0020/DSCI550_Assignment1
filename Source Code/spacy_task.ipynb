{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "qqtx1hN-82In",
        "outputId": "257e5748-1fb6-45c8-e47a-5c7eef2ead76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.2.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n",
            "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-25.0.1 setuptools-78.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "f5572ecff7114e898ae0baf3e14c5154"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n",
            "^C\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ecBDIBiLR0u",
        "outputId": "5005d893-5c44-47a4-c661-e7f3ecb61a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Install tqdm if not already installed\n",
        "!pip install tqdm\n",
        "\n",
        "# Enable tqdm for pandas\n",
        "tqdm.pandas()\n",
        "\n",
        "# Load SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load Haunted Places dataset\n",
        "df = pd.read_csv(\"./haunted_places_v2.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Function to extract all named entities and organize them\n",
        "def extract_entities(text):\n",
        "    doc = nlp(str(text))\n",
        "    all_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    persons = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
        "    orgs = [ent.text for ent in doc.ents if ent.label_ == \"ORG\"]\n",
        "    locations = [ent.text for ent in doc.ents if ent.label_ in (\"GPE\", \"LOC\", \"FAC\")]\n",
        "    return pd.Series([str(all_entities), str(persons), str(orgs), str(locations)])\n",
        "\n",
        "# Apply extraction function with progress bar\n",
        "df[[\"NER_ENTITIES\", \"NER_PERSONS\", \"NER_ORGS\", \"NER_LOCATIONS\"]] = df[\"description\"].progress_apply(extract_entities)\n",
        "\n",
        "# Save the updated dataset as TSV\n",
        "df.to_csv(\"haunted_places_v2.tsv\", sep='\t', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqDRyCvI9qcT",
        "outputId": "bf382c3d-8de6-4752-9a2e-842909f523f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10992/10992 [03:41<00:00, 49.60it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Function to compute percentage of non-empty entries in a given column\n",
        "def percent_with_entities(column_name):\n",
        "    return df[column_name].apply(lambda x: len(ast.literal_eval(x)) > 0).mean() * 100\n",
        "\n",
        "# Compute percentage for each entity category\n",
        "percent_entities = percent_with_entities(\"NER_ENTITIES\")\n",
        "percent_persons = percent_with_entities(\"NER_PERSONS\")\n",
        "percent_orgs = percent_with_entities(\"NER_ORGS\")\n",
        "percent_locations = percent_with_entities(\"NER_LOCATIONS\")\n",
        "\n",
        "# Print results\n",
        "print(f\"Percentage with at least one entity (any type):   {percent_entities:.2f}%\")\n",
        "print(f\"Percentage with at least one PERSON entity:       {percent_persons:.2f}%\")\n",
        "print(f\"Percentage with at least one ORG entity:          {percent_orgs:.2f}%\")\n",
        "print(f\"Percentage with at least one LOCATION entity:     {percent_locations:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X89FHez738yT",
        "outputId": "afa9fb3c-5847-4e9f-ffdc-b9f4a65347a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage with at least one entity (any type):   83.43%\n",
            "Percentage with at least one PERSON entity:       26.14%\n",
            "Percentage with at least one ORG entity:          26.96%\n",
            "Percentage with at least one LOCATION entity:     21.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import ast\n",
        "\n",
        "# Load the updated dataset\n",
        "df = pd.read_csv(\"./haunted_places_v2.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Convert stringified lists to Python lists\n",
        "for col in [\"NER_ENTITIES\", \"NER_PERSONS\", \"NER_ORGS\", \"NER_LOCATIONS\"]:\n",
        "    df[col] = df[col].apply(ast.literal_eval)\n",
        "\n",
        "# Top Locations of Places\n",
        "location_counter = Counter()\n",
        "for locs in df[\"NER_LOCATIONS\"]:\n",
        "    location_counter.update(locs)\n",
        "\n",
        "top_locations = location_counter.most_common(10)\n",
        "print(\"Top 10 Mentioned Locations in Haunted Place Descriptions:\")\n",
        "for i, (loc, count) in enumerate(top_locations, 1):\n",
        "    print(f\"{i}. {loc}: {count} times\")\n",
        "\n",
        "# Looking at Cities matching Locations\n",
        "if \"city\" in df.columns:\n",
        "    df[\"city_match_in_locations\"] = df.apply(\n",
        "        lambda row: row[\"city\"] in row[\"NER_LOCATIONS\"] if pd.notnull(row[\"city\"]) else False,\n",
        "        axis=1\n",
        "    )\n",
        "    match_count = df[\"city_match_in_locations\"].sum()\n",
        "    total_rows = len(df)\n",
        "    match_rate = match_count / total_rows\n",
        "\n",
        "    print(f\"Cities Found in Location Entities: {match_count}/{total_rows} rows\")\n",
        "    print(f\"Proportion of rows where the city is mentioned in the extracted location entities: {match_rate:.2%}\")\n",
        "else:\n",
        "    print(\"No 'city' column found to correlate with NER_LOCATIONS.\")\n",
        "\n",
        "# PERSON Entity Analysis – Contextual Insight\n",
        "df[\"person_entity_count\"] = df[\"NER_PERSONS\"].apply(len)\n",
        "avg_persons = df[\"person_entity_count\"].mean()\n",
        "percent_with_persons = (df[\"person_entity_count\"] > 0).mean() * 100\n",
        "max_persons = df[\"person_entity_count\"].max()\n",
        "num_with_multiple = (df[\"person_entity_count\"] >= 3).sum()\n",
        "\n",
        "print(\"\\nAnalysis of PERSON Entities in Haunted Place Descriptions:\")\n",
        "print(f\"- Average PERSON entities per description: {avg_persons:.2f}\")\n",
        "print(f\"- % of entries with at least one PERSON: {percent_with_persons:.2f}%\")\n",
        "print(f\"- Max PERSON entities in a single description: {max_persons}\")\n",
        "print(f\"- Entries with 3 or more PERSON mentions: {num_with_multiple} ({num_with_multiple / len(df):.2%} of entries)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO7kT3-bM35O",
        "outputId": "2fc8b580-5406-4bf1-b01e-7176dae2e4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Mentioned Locations in Haunted Place Descriptions:\n",
            "1. Washington: 22 times\n",
            "2. Chicago: 21 times\n",
            "3. US: 19 times\n",
            "4. Mansion: 19 times\n",
            "5. Ohio: 18 times\n",
            "6. Main Street: 18 times\n",
            "7. Auditorium: 17 times\n",
            "8. Michigan: 16 times\n",
            "9. East: 15 times\n",
            "10. Texas: 14 times\n",
            "Cities Found in Location Entities: 531/10992 rows\n",
            "Proportion of rows where the city is mentioned in the extracted location entities: 4.83%\n",
            "\n",
            "Analysis of PERSON Entities in Haunted Place Descriptions:\n",
            "- Average PERSON entities per description: 0.42\n",
            "- % of entries with at least one PERSON: 26.14%\n",
            "- Max PERSON entities in a single description: 17\n",
            "- Entries with 3 or more PERSON mentions: 375 (3.41% of entries)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "# Load both datasets\n",
        "df_haunted = pd.read_csv(\"haunted_places_v2_tsv\", sep=\"\\t\"')\n",
        "df_captions = pd.read_csv(\"output_with_captions.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Convert the NER_ENTITIES column\n",
        "df_haunted[\"NER_ENTITIES\"] = df_haunted[\"NER_ENTITIES\"].apply(ast.literal_eval)\n",
        "\n",
        "# Extract just the entity text from the NER_ENTITIES list\n",
        "df_haunted[\"entity_texts\"] = df_haunted[\"NER_ENTITIES\"].apply(lambda ents: [ent[0] for ent in ents])\n",
        "\n",
        "# Combine the two datasets for row-wise comparison\n",
        "df_combined = pd.concat([df_haunted, df_captions], axis=1)\n",
        "\n",
        "# Check if any entity text is found in the corresponding caption (case insensitive)\n",
        "def has_entity_in_caption(entity_list, caption):\n",
        "    caption_lower = str(caption).lower()\n",
        "    return any(entity.lower() in caption_lower for entity in entity_list)\n",
        "\n",
        "df_combined[\"entity_in_caption\"] = df_combined.apply(\n",
        "    lambda row: has_entity_in_caption(row[\"entity_texts\"], row[\"caption\"]),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Count how many captions contain at least one identified entity\n",
        "count_with_entity = df_combined[\"entity_in_caption\"].sum()\n",
        "total_rows = len(df_combined)\n",
        "percentage = (count_with_entity / total_rows) * 100\n",
        "\n",
        "print(f\" {count_with_entity} out of {total_rows} captions ({percentage:.2f}%) contain at least one identified entity from the corresponding haunted place description.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGmDiracUFDL",
        "outputId": "502d7059-14ad-4160-bcd7-5478e8af37fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 2378 out of 10992 captions (21.63%) contain at least one identified entity from the corresponding haunted place description.\n"
          ]
        }
      ]
    }
  ]
}
